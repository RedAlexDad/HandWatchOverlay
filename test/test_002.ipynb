{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad96261-86e4-4a63-85d9-3f4868c7ef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 10:15:27.367701: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-24 10:15:27.367859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-24 10:15:27.465665: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-24 10:15:27.670360: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-24 10:15:28.777157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68348c7d-8c91-4758-8d39-0834db414e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список путей к изображениям часов\n",
    "watch_images = [\n",
    "    \"watch1.png\",\n",
    "    # \"watch2.png\",\n",
    "    # ... Добавьте больше изображений часов\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2050b868-8947-4d50-9611-fe13a175795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка изображений часов\n",
    "watches = [cv2.imread(path) for path in watch_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae97c68-b704-4741-896a-e408b73a382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@499.849] global cap_v4l.cpp:997 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@499.850] global obsensor_uvc_stream_channel.cpp:159 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "# Инициализация захвата видео с веб-камеры\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd120212-746b-4fb7-a799-dbb1097d3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для выбора часов (пример с использованием щелчка мыши)\n",
    "def select_watch(event, x, y, flags, param):\n",
    "    global selected_watch\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Пример использования щелчка мыши\n",
    "        for i, watch in enumerate(watches):\n",
    "            if y in range(i * 50, (i + 1) * 50):  # Предполагаем, что часы отображаются вертикально\n",
    "                selected_watch = i\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b4fd47-34ef-4fea-a1c7-315cab902bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Инициализация рук медиапайпа\n",
    "mp_hands = mp.solutions.hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192b4541-f52e-4c78-829c-8c70143652dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной цикл\n",
    "selected_watch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20950f35-a934-4189-aea4-2e10e5c0bb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not capture frame from video stream.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Проверьте, был ли кадр успешно прочитан\n",
    "    if ret:\n",
    "        # Преобразовать кадр в формат RGB для MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Обнаруживать руки\n",
    "        results = mp_hands.process(frame_rgb)\n",
    "    \n",
    "        # Если обнаружена рука\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Получить координаты ориентира на запястье\n",
    "                wrist_x = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * frame.shape[1])\n",
    "                wrist_y = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * frame.shape[0])\n",
    "                \n",
    "                # Нарисуйте круг на запястье для визуализации\n",
    "                cv2.circle(frame, (wrist_x, wrist_y), 5, (0, 255, 0), -1)\n",
    "    \n",
    "                # Наложение часов, если выбрано\n",
    "                if selected_watch is not None:\n",
    "                    watch_img = watches[selected_watch]\n",
    "    \n",
    "                    # Resize watch based on wrist distance to middle finger (approximate)\n",
    "                    middle_finger_x = int(hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x * frame.shape[1])\n",
    "                    wrist_to_finger_dist = abs(wrist_x - middle_finger_x)\n",
    "                    watch_width = int(wrist_to_finger_dist * 1.5)  # Adjust scaling factor as needed\n",
    "                    watch_height = int(watch_width * watch_img.shape[0] / watch_img.shape[1])\n",
    "                    resized_watch = cv2.resize(watch_img, (watch_width, watch_height))\n",
    "    \n",
    "                    # Overlay watch using alpha blending\n",
    "                    alpha = 0.7  # Adjust transparency as needed\n",
    "                    beta = 1 - alpha\n",
    "                    overlay_region = frame[wrist_y - watch_height//2:wrist_y + watch_height//2, \n",
    "                                           wrist_x - watch_width//2:wrist_x + watch_width//2]\n",
    "                    frame[wrist_y - watch_height//2:wrist_y + watch_height//2, \n",
    "                          wrist_x - watch_width//2:wrist_x + watch_width//2] = cv2.addWeighted(overlay_region, alpha, resized_watch, beta, 0.0)\n",
    "    \n",
    "    \n",
    "        # Отображение результата\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "        # Выход из цикла при нажатии клавиши \"q\"\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        print(\"Error: Could not capture frame from video stream.\")\n",
    "        break  # Exit the loop if no frame is captured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ab908-b62f-46b4-b11b-bf5162a278fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
